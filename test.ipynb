{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58ca7d3e-219d-4550-88bd-68f0c4e99a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Path to your SQLite database\n",
    "db_path = \"stock_data.db\"\n",
    "engine = create_engine(f\"sqlite:///{db_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2dfa1870-2a5b-4901-a951-f7f3921aec0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ticker        date       open       high        low      close adj_close  \\\n",
      "375   IBIT  2025-07-14  69.169998  69.459999  67.735001  68.180000      None   \n",
      "376   IBIT  2025-07-15  66.930000  67.400002  65.769997  66.160004      None   \n",
      "377   IBIT  2025-07-16  67.550003  68.239998  67.141998  67.830002      None   \n",
      "378   IBIT  2025-07-17  67.035004  68.214996  66.820000  67.650002      None   \n",
      "379   IBIT  2025-07-18  67.535004  67.837502  66.544998  66.680000      None   \n",
      "\n",
      "         volume  macd macd_signal  ... bbands_middle bbands_lower stoch_k  \\\n",
      "375  68391600.0  None        None  ...          None         None    None   \n",
      "376  82079400.0  None        None  ...          None         None    None   \n",
      "377  58927000.0  None        None  ...          None         None    None   \n",
      "378  45310300.0  None        None  ...          None         None    None   \n",
      "379  49758396.0  None        None  ...          None         None    None   \n",
      "\n",
      "    stoch_d   cci   adx   obv ema_20 ema_50   roc  \n",
      "375    None  None  None  None   None   None  None  \n",
      "376    None  None  None  None   None   None  None  \n",
      "377    None  None  None  None   None   None  None  \n",
      "378    None  None  None  None   None   None  None  \n",
      "379    None  None  None  None   None   None  None  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load all data for MSFT\n",
    "df = pd.read_sql(\"SELECT * FROM stock_data WHERE ticker='IBIT' ORDER BY date\", engine)\n",
    "print(df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02a3feee-9ff9-4061-a53d-20f0b02042e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 2164 rows into 'tickers' table.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Load tickers.csv\n",
    "df = pd.read_csv(\"etf.csv\")\n",
    "# Normalize column names (optional)\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Connect to SQLite and write table\n",
    "engine = create_engine(\"sqlite:///stock_data.db\")\n",
    "df.to_sql(\"symbol\", engine, if_exists=\"replace\", index=False)\n",
    "print(f\"Inserted {len(df)} rows into 'tickers' table.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c94f265-0ef0-42a7-83cf-f6be93a9f8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unnamed: 0 symbol\n",
      "0           0   SPDV\n",
      "1           1   EEMD\n",
      "2           2    ZIG\n",
      "3           3   HDGE\n",
      "4           4   DWSH\n"
     ]
    }
   ],
   "source": [
    "tickers = pd.read_sql(\"SELECT * FROM symbol\", engine)\n",
    "print(tickers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b09baf1-c2a5-4b2e-94e7-9aeb38f8df05",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'readl_sql'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load MSFT data for 2020 only\u001b[39;00m\n\u001b[1;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m    SELECT * FROM stock_data\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m    WHERE ticker = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTLT\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m    AND date >= \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2020-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m AND date <= \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2020-12-31\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m    ORDER BY date\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m df_range \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadl_sql\u001b[49m(query, engine)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_range)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'readl_sql'"
     ]
    }
   ],
   "source": [
    "# Load MSFT data for 2020 only\n",
    "query = \"\"\"\n",
    "    SELECT * FROM stock_data\n",
    "    WHERE ticker = 'TLT'\n",
    "    AND date >= '2020-01-01' AND date <= '2020-12-31'\n",
    "    ORDER BY date\n",
    "\"\"\"\n",
    "df_range = pd.readl_sql(query, engine)\n",
    "print(df_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3fa1b57-068b-4030-8011-6c095d260b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Symbol' not found! Check your DataFrame columns: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "url = \"http://www.nasdaqtrader.com/dynamic/SymDir/etf.txt\"\n",
    "response = requests.get(url)\n",
    "lines = response.text.strip().splitlines()\n",
    "\n",
    "# Filter out non-data lines\n",
    "data_lines = [line for line in lines if '|' in line and not line.startswith('#')]\n",
    "clean_text = '\\n'.join(data_lines)\n",
    "\n",
    "df = pd.read_csv(StringIO(clean_text), sep='|')\n",
    "\n",
    "df.columns = df.columns.str.strip()   # <<--- Strip whitespace from columns\n",
    "\n",
    "# Remove empty columns and rows\n",
    "df = df.dropna(how=\"all\", axis=1)\n",
    "if 'Symbol' in df.columns:\n",
    "    df = df[df['Symbol'].astype(str).str.strip().str.len() > 0]\n",
    "\n",
    "    # Show first 10 tickers and names\n",
    "    print(df[['Symbol', 'Security Name']].head(10))\n",
    "\n",
    "    # Get all ETF tickers\n",
    "    etf_tickers = df['Symbol'].tolist()\n",
    "else:\n",
    "    print(\"Column 'Symbol' not found! Check your DataFrame columns:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "107359b3-0895-40fe-b53c-29e1383c610e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting investpy\n",
      "  Downloading investpy-1.0.8.tar.gz (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting Unidecode>=1.1.1 (from investpy)\n",
      "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: setuptools>=41.2.0 in /home/zhubo/my-conda-envs/sam2/lib/python3.10/site-packages (from investpy) (75.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/zhubo/my-conda-envs/sam2/lib/python3.10/site-packages (from investpy) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.25.1 in /home/zhubo/my-conda-envs/sam2/lib/python3.10/site-packages (from investpy) (2.2.3)\n",
      "Requirement already satisfied: lxml>=4.4.1 in /home/zhubo/my-conda-envs/sam2/lib/python3.10/site-packages (from investpy) (5.3.1)\n",
      "Requirement already satisfied: requests>=2.22.0 in /home/zhubo/my-conda-envs/sam2/lib/python3.10/site-packages (from investpy) (2.32.3)\n",
      "Requirement already satisfied: pytz>=2019.3 in /home/zhubo/my-conda-envs/sam2/lib/python3.10/site-packages (from investpy) (2025.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/zhubo/my-conda-envs/sam2/lib/python3.10/site-packages (from pandas>=0.25.1->investpy) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/zhubo/my-conda-envs/sam2/lib/python3.10/site-packages (from pandas>=0.25.1->investpy) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zhubo/my-conda-envs/sam2/lib/python3.10/site-packages (from requests>=2.22.0->investpy) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zhubo/my-conda-envs/sam2/lib/python3.10/site-packages (from requests>=2.22.0->investpy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zhubo/my-conda-envs/sam2/lib/python3.10/site-packages (from requests>=2.22.0->investpy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zhubo/my-conda-envs/sam2/lib/python3.10/site-packages (from requests>=2.22.0->investpy) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /home/zhubo/my-conda-envs/sam2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.25.1->investpy) (1.17.0)\n",
      "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
      "Building wheels for collected packages: investpy\n",
      "  Building wheel for investpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for investpy: filename=investpy-1.0.8-py3-none-any.whl size=4481641 sha256=7d9a85cad7d451723daedc65eb54c774c7f0e46016cfdcdcfbe457f0d2b25275\n",
      "  Stored in directory: /home/zhubo/.cache/pip/wheels/db/f4/ae/980b93b0257620bc8e4afc98a854a7a746a33eb8335fd07906\n",
      "Successfully built investpy\n",
      "Installing collected packages: Unidecode, investpy\n",
      "Successfully installed Unidecode-1.4.0 investpy-1.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install investpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84b4a739-1e24-4ca7-afe0-74923722dffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2164"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(etfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee3f7b2b-c410-42d6-804a-1cae4fc180a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import investpy\n",
    "etfs = investpy.etfs.get_etfs(country='united states')\n",
    "etfs.to_csv('all_etf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a017c4e-346d-4042-bc24-27f61b27e1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique stocks in DB: 2148\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "db_path = \"stock_data.db\"\n",
    "engine = create_engine(f\"sqlite:///{db_path}\")\n",
    "\n",
    "# Count number of unique tickers\n",
    "df = pd.read_sql(\"SELECT COUNT(DISTINCT ticker) as num_stocks FROM stock_data\", engine)\n",
    "print(f\"Number of unique stocks in DB: {df['num_stocks'][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f0227a7-1bba-4923-b79f-3614c1dde9d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AAAU: Checking for missing features...\n",
      "  Calculating features for 1739 / 1739 rows...\n",
      "  Updated 1739 rows.\n",
      "\n",
      "AADR: Checking for missing features...\n",
      "  Calculating features for 2513 / 2513 rows...\n",
      "  Updated 2513 rows.\n",
      "\n",
      "AAXJ: Checking for missing features...\n",
      "  Calculating features for 2513 / 2513 rows...\n",
      "  Updated 2513 rows.\n",
      "\n",
      "ACES: Checking for missing features...\n",
      "  Calculating features for 1771 / 1771 rows...\n",
      "  Updated 1771 rows.\n",
      "\n",
      "ACIO: Checking for missing features...\n",
      "  Calculating features for 1514 / 1514 rows...\n",
      "  Updated 1514 rows.\n",
      "\n",
      "ACSG: Checking for missing features...\n",
      "  Calculating features for 1662 / 1662 rows...\n",
      "  Updated 1662 rows.\n",
      "\n",
      "ACSI: Checking for missing features...\n",
      "  Calculating features for 2184 / 2184 rows...\n",
      "  Updated 2184 rows.\n",
      "\n",
      "ACT: Checking for missing features...\n",
      "  Calculating features for 962 / 962 rows...\n",
      "  Updated 962 rows.\n",
      "\n",
      "ACWF: Checking for missing features...\n",
      "  Calculating features for 2513 / 2513 rows...\n",
      "  Updated 2513 rows.\n",
      "\n",
      "ACWI: Checking for missing features...\n",
      "  Calculating features for 2513 / 2513 rows...\n",
      "  Updated 2513 rows.\n",
      "\n",
      "ACWV: Checking for missing features...\n",
      "  Calculating features for 2513 / 2513 rows...\n",
      "  Updated 2513 rows.\n",
      "\n",
      "ACWX: Checking for missing features...\n",
      "  Calculating features for 2513 / 2513 rows...\n",
      "  Updated 2513 rows.\n",
      "\n",
      "ADRD: Checking for missing features...\n",
      "  Calculating features for 1160 / 1160 rows...\n",
      "  Updated 1160 rows.\n",
      "\n",
      "ADRE: Checking for missing features...\n",
      "  Calculating features for 1943 / 1943 rows...\n",
      "  Updated 1943 rows.\n",
      "\n",
      "ADRU: Checking for missing features...\n",
      "  Calculating features for 1160 / 1160 rows...\n",
      "  Updated 1160 rows.\n",
      "\n",
      "AFIF: Checking for missing features...\n",
      "  Calculating features for 1706 / 1706 rows...\n",
      "  Updated 1706 rows.\n",
      "\n",
      "AFK: Checking for missing features...\n",
      "  Calculating features for 2514 / 2514 rows...\n",
      "  Updated 2514 rows.\n",
      "\n",
      "AFTY: Checking for missing features...\n",
      "  Calculating features for 2324 / 2324 rows...\n",
      "  Updated 2324 rows.\n",
      "\n",
      "AGF: Checking for missing features...\n",
      "  Calculating features for 2513 / 2513 rows...\n",
      "  Updated 2513 rows.\n",
      "\n",
      "AGG: Checking for missing features...\n",
      "  Calculating features for 2513 / 2513 rows...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 111\u001b[0m\n\u001b[1;32m    109\u001b[0m             update_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    110\u001b[0m             set_clause \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m = :\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m feat \u001b[38;5;129;01min\u001b[39;00m feature_columns])\n\u001b[0;32m--> 111\u001b[0m             \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;43m                    UPDATE stock_data SET \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mset_clause\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;43m                    WHERE ticker = :ticker AND date = :date\u001b[39;49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m                \u001b[49m\u001b[43mupdate_dict\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Updated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(to_update)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll done! All technical features are up-to-date in your database.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/my-conda-envs/sam2/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1415\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1416\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my-conda-envs/sam2/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:523\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    522\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[0;32m--> 523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/my-conda-envs/sam2/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1629\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1621\u001b[0m schema_translate_map \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1622\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschema_translate_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1623\u001b[0m )\n\u001b[1;32m   1625\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1626\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[1;32m   1627\u001b[0m )\n\u001b[0;32m-> 1629\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m \u001b[43melem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_w_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompiled_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfor_executemany\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfor_executemany\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema_translate_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_translate_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlinting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompiler_linting\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcompiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWARN_LINTING\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1637\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_context(\n\u001b[1;32m   1638\u001b[0m     dialect,\n\u001b[1;32m   1639\u001b[0m     dialect\u001b[38;5;241m.\u001b[39mexecution_ctx_cls\u001b[38;5;241m.\u001b[39m_init_compiled,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     cache_hit\u001b[38;5;241m=\u001b[39mcache_hit,\n\u001b[1;32m   1648\u001b[0m )\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n",
      "File \u001b[0;32m~/my-conda-envs/sam2/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:691\u001b[0m, in \u001b[0;36mClauseElement._compile_w_cache\u001b[0;34m(self, dialect, compiled_cache, column_keys, for_executemany, schema_translate_map, **kw)\u001b[0m\n\u001b[1;32m    688\u001b[0m elem_cache_key: Optional[CacheKey]\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compiled_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39m_supports_statement_cache:\n\u001b[0;32m--> 691\u001b[0m     elem_cache_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_cache_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    693\u001b[0m     elem_cache_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/my-conda-envs/sam2/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:1351\u001b[0m, in \u001b[0;36mHasMemoized.memoized_instancemethod.<locals>.oneshot\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moneshot\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m-> 1351\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1353\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmemo\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m   1354\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/my-conda-envs/sam2/lib/python3.10/site-packages/sqlalchemy/sql/cache_key.py:413\u001b[0m, in \u001b[0;36mMemoizedHasCacheKey._generate_cache_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;129m@HasMemoized\u001b[39m\u001b[38;5;241m.\u001b[39mmemoized_instancemethod\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate_cache_key\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[CacheKey]:\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHasCacheKey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_cache_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my-conda-envs/sam2/lib/python3.10/site-packages/sqlalchemy/sql/cache_key.py:382\u001b[0m, in \u001b[0;36mHasCacheKey._generate_cache_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m bindparams: List[BindParameter[Any]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    381\u001b[0m _anon_map \u001b[38;5;241m=\u001b[39m anon_map()\n\u001b[0;32m--> 382\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gen_cache_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_anon_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbindparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m NO_CACHE \u001b[38;5;129;01min\u001b[39;00m _anon_map:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/my-conda-envs/sam2/lib/python3.10/site-packages/sqlalchemy/sql/cache_key.py:302\u001b[0m, in \u001b[0;36mHasCacheKey._gen_cache_key\u001b[0;34m(self, anon_map, bindparams)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meth \u001b[38;5;129;01mis\u001b[39;00m CACHE_IN_PLACE:\n\u001b[1;32m    301\u001b[0m     result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (attrname, obj)\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;129;01mis\u001b[39;00m PROPAGATE_ATTRS:\n\u001b[1;32m    303\u001b[0m     result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    304\u001b[0m         attrname,\n\u001b[1;32m    305\u001b[0m         obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompile_state_plugin\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m         ),\n\u001b[1;32m    313\u001b[0m     )\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;129;01mis\u001b[39;00m InternalTraversal\u001b[38;5;241m.\u001b[39mdp_annotations_key:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# obj is here is the _annotations dict.  Table uses\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# a memoized version of it.  however in other cases,\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# we generate it given anon_map as we may be from a\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# Join, Aliased, etc.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# see #8790\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Batch Adds Technical Features to Each Stock in SQLite DB\n",
    "--------------------------------------------------------\n",
    "- Uses pandas-ta for classic technical indicators (MACD, RSI, ATR, etc.)\n",
    "- Only adds columns if missing\n",
    "- Only updates rows missing features (existing values not overwritten)\n",
    "- No look-ahead bias or leakage\n",
    "Requires: pandas, pandas-ta, sqlalchemy\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# -- CONFIG --\n",
    "db_path = \"stock_data.db\"\n",
    "feature_columns = [\n",
    "    'macd', 'macd_signal', 'macd_hist',\n",
    "    'rsi', 'atr',\n",
    "    'bbands_upper', 'bbands_middle', 'bbands_lower',\n",
    "    'stoch_k', 'stoch_d',\n",
    "    'cci', 'adx', 'obv', 'ema_20', 'ema_50', 'roc'\n",
    "]\n",
    "\n",
    "# -- 1. Connect to DB --\n",
    "engine = create_engine(f\"sqlite:///{db_path}\")\n",
    "\n",
    "# -- 2. Add missing feature columns to the table --\n",
    "with engine.connect() as conn:\n",
    "    existing_cols = pd.read_sql(\"PRAGMA table_info(stock_data);\", conn)['name'].tolist()\n",
    "with engine.begin() as conn:\n",
    "    for feat in feature_columns:\n",
    "        if feat not in existing_cols:\n",
    "            print(f\"Adding column {feat} ...\")\n",
    "            try:\n",
    "                conn.execute(text(f\"ALTER TABLE stock_data ADD COLUMN {feat} REAL\"))\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to add {feat}: {e}\")\n",
    "\n",
    "# -- 3. Define the calculation function (no look-ahead bias) --\n",
    "def calc_features(df):\n",
    "    # MACD\n",
    "    macd = ta.macd(df['close'])\n",
    "    df['macd'] = macd.iloc[:, 0] if 'MACD_12_26_9' in macd.columns else macd.iloc[:, 0]\n",
    "    df['macd_signal'] = macd.iloc[:, 1] if 'MACDs_12_26_9' in macd.columns else macd.iloc[:, 1]\n",
    "    df['macd_hist'] = macd.iloc[:, 2] if 'MACDh_12_26_9' in macd.columns else macd.iloc[:, 2]\n",
    "    # RSI\n",
    "    df['rsi'] = ta.rsi(df['close'])\n",
    "    # ATR\n",
    "    df['atr'] = ta.atr(df['high'], df['low'], df['close'])\n",
    "    # Bollinger Bands (robust to col names)\n",
    "    bb = ta.bbands(df['close'])\n",
    "    bb_upper = [col for col in bb.columns if col.startswith(\"BBU_\")]\n",
    "    bb_middle = [col for col in bb.columns if col.startswith(\"BBM_\")]\n",
    "    bb_lower = [col for col in bb.columns if col.startswith(\"BBL_\")]\n",
    "    df['bbands_upper'] = bb[bb_upper[0]] if bb_upper else None\n",
    "    df['bbands_middle'] = bb[bb_middle[0]] if bb_middle else None\n",
    "    df['bbands_lower'] = bb[bb_lower[0]] if bb_lower else None\n",
    "    # Stochastic Oscillator\n",
    "    stoch = ta.stoch(df['high'], df['low'], df['close'])\n",
    "    stoch_k = [col for col in stoch.columns if col.startswith(\"STOCHk_\")]\n",
    "    stoch_d = [col for col in stoch.columns if col.startswith(\"STOCHd_\")]\n",
    "    df['stoch_k'] = stoch[stoch_k[0]] if stoch_k else None\n",
    "    df['stoch_d'] = stoch[stoch_d[0]] if stoch_d else None\n",
    "    # CCI\n",
    "    df['cci'] = ta.cci(df['high'], df['low'], df['close'])\n",
    "    # ADX\n",
    "    adx = ta.adx(df['high'], df['low'], df['close'])\n",
    "    adx_col = [col for col in adx.columns if col.startswith(\"ADX_\")]\n",
    "    df['adx'] = adx[adx_col[0]] if adx_col else None\n",
    "    # OBV\n",
    "    df['obv'] = ta.obv(df['close'], df['volume'])\n",
    "    # EMA 20, EMA 50\n",
    "    df['ema_20'] = ta.ema(df['close'], length=20)\n",
    "    df['ema_50'] = ta.ema(df['close'], length=50)\n",
    "    # ROC\n",
    "    df['roc'] = ta.roc(df['close'])\n",
    "    return df\n",
    "\n",
    "\n",
    "# -- 4. Main loop: for each ticker, update only missing features --\n",
    "tickers = pd.read_sql(\"SELECT DISTINCT ticker FROM stock_data\", engine)['ticker'].tolist()\n",
    "for ticker in tickers:\n",
    "    print(f\"\\n{ticker}: Checking for missing features...\")\n",
    "    # Only load necessary columns\n",
    "    df = pd.read_sql(\n",
    "        f\"SELECT date, open, high, low, close, volume, {','.join(feature_columns)} FROM stock_data WHERE ticker = ? ORDER BY date\",\n",
    "        engine, params=(ticker,))\n",
    "    if df.empty:\n",
    "        continue\n",
    "    # Identify rows with missing features\n",
    "    missing_mask = df[feature_columns].isnull().any(axis=1)\n",
    "    if not missing_mask.any():\n",
    "        print(f\"  All features already present.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"  Calculating features for {missing_mask.sum()} / {len(df)} rows...\")\n",
    "    # Calculate features (safe for look-ahead, uses only past and present)\n",
    "    df_features = calc_features(df)\n",
    "\n",
    "    # Only update rows that were missing\n",
    "    to_update = df_features[missing_mask].copy()\n",
    "\n",
    "    # Write back only needed features (do not overwrite existing values)\n",
    "    with engine.begin() as conn:\n",
    "        for _, row in to_update.iterrows():\n",
    "            update_dict = {feat: None if pd.isna(row[feat]) else float(row[feat]) for feat in feature_columns}\n",
    "            update_dict['ticker'] = ticker\n",
    "            update_dict['date'] = row['date']\n",
    "            set_clause = ', '.join([f\"{feat} = :{feat}\" for feat in feature_columns])\n",
    "            conn.execute(\n",
    "                text(f\"\"\"\n",
    "                    UPDATE stock_data SET {set_clause}\n",
    "                    WHERE ticker = :ticker AND date = :date\n",
    "                \"\"\"),\n",
    "                update_dict\n",
    "            )\n",
    "    print(f\"  Updated {len(to_update)} rows.\")\n",
    "\n",
    "print(\"\\nAll done! All technical features are up-to-date in your database.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sam2]",
   "language": "python",
   "name": "conda-env-sam2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
